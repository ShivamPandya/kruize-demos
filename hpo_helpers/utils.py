import os
import json
import yaml
import csv
import copy
import subprocess
from datatest import validate

datafiles = []
dir_path = 'autotune-configs'
ext = ('.json')

## Convert the tunable config generated by HPO to JDK_JAVA_OPTIONS
def convert2envoptions(data):
    global JDK_JAVA_OPTIONS, cpureq, memreq
    tunables_jvm_boolean = ["TieredCompilation", "AllowParallelDefineClass", "AllowVectorizeOnDemand", "AlwaysCompileLoopMethods", "AlwaysPreTouch", "AlwaysTenure", "BackgroundCompilation", "DoEscapeAnalysis", "UseInlineCaches", "UseLoopPredicate", "UseStringDeduplication", "UseSuperWord", "UseTypeSpeculation"]
    tunables_jvm_values = ["FreqInlineSize", "MaxInlineLevel", "MinInliningThreshold", "CompileThreshold", "CompileThresholdScaling", "ConcGCThreads", "InlineSmallCode", "LoopUnrollLimit", "LoopUnrollMin", "MinSurvivorRatio", "NewRatio", "TieredStopAtLevel"]
    tunables_quarkus = ["quarkustpcorethreads", "quarkustpqueuesize", "quarkusdatasourcejdbcminsize", "quarkusdatasourcejdbcmaxsize"]
    JDK_JAVA_OPTIONS = ""

    with open(data) as data_file:
        sstunables = json.load(data_file)

    for st in sstunables:
        for btunable in tunables_jvm_boolean:
            if btunable == st["tunable_name"]:
                if st["tunable_value"] == "true":
                    JDK_JAVA_OPTIONS = JDK_JAVA_OPTIONS + " -XX:+" + btunable
                elif st["tunable_value"] == "false":
                    JDK_JAVA_OPTIONS = JDK_JAVA_OPTIONS + " -XX:-" + btunable
        for jvtunable in tunables_jvm_values:
            if jvtunable == st["tunable_name"]:
                JDK_JAVA_OPTIONS = JDK_JAVA_OPTIONS + " -XX:" + jvtunable + "=" + str(st["tunable_value"])
                
        for qtunable in tunables_quarkus:
            if qtunable == st["tunable_name"]:
                if qtunable == "quarkustpcorethreads":
                    JDK_JAVA_OPTIONS = JDK_JAVA_OPTIONS + " -Dquarkus.thread-pool.core-threads=" + st["tunable_value"]
                elif qtunable == "quarkustpqueuesize":
                    JDK_JAVA_OPTIONS = JDK_JAVA_OPTIONS + " -Dquarkus.thread-pool.queue-size=" + st["tunable_value"]
                elif qtunable == "quarkusdatasourcejdbcminsize":
                    JDK_JAVA_OPTIONS = JDK_JAVA_OPTIONS + " -Dquarkus.datasource.jdbc.min-size" + st["tunable_value"]
                elif qtunable == "quarkusdatasourcejdbcmaxsize":
                    JDK_JAVA_OPTIONS = JDK_JAVA_OPTIONS + " -Dquarkus.datasource.jdbc.max-size" + st["tunable_value"]

        if st["tunable_name"] == "cpuRequest":
            cpureq = str(st["tunable_value"])
        elif st["tunable_name"] == "memoryRequest":
            memreq = str(st["tunable_value"])

    #print("Set cpu requests and limits to " + cpureq)
    #print("Set memory requests and limits to " + memreq + "Mi")
    #print("Update your env of the benchmark yaml to use the below tunables")
    #print("JDK_JAVA_OPTIONS=" + str(JDK_JAVA_OPTIONS))
    envlist = []
    envlist.append(cpureq)
    envlist.append(memreq)
    envlist.append(str(JDK_JAVA_OPTIONS))
    print(envlist)


def calcobj(searchspacejson , outputcsvfile):
    funcvariables = []
    
    with open(searchspacejson) as f:
        sdata1 = json.load(f)

        for sdata in sdata1:
            ## Get objective function
            if sdata == "objective_function":
                objf = sdata1["objective_function"]
            ## Get function variables
            elif sdata == "function_variables":
                funcvar = sdata1["function_variables"]
                for fvar in funcvar:
                    for fkeys in fvar.keys():
                        if(fkeys == "name"):
                            funcvariables.append(fvar.get(fkeys))
    ## Print obj function, function variables and list of metrics with score values
    #print(objf)
    #print(funcvariables)

    with open(outputcsvfile, 'r', newline='') as csvfile:
        reader = csv.DictReader(csvfile, delimiter=',')
        #rows = [ { k.strip(): v.strip() for k,v in row.items() } for row in reader ]
        #csvheader = rows[0].keys()
        csvheader = reader.fieldnames
        #validate(csvheader , headerlist)
        for row in reader:
            for x in funcvariables:
                for k,v in row.items():
                    if (k == x):
                        objf = objf.replace(x , v)
    try:
        print(eval(objf))
    except:
        print("-1")
    
def getexperimentid(searchspacejson):
    with open(searchspacejson) as f:
        sdata = json.load(f)
        for sd in sdata:
            ## Get experiment id
            if sd == "experiment_id":
                eid = sdata["experiment_id"]
    print(eid)

def gettrials(searchspacejson):
    with open(searchspacejson) as f:
        sdata = json.load(f)
        for sd in sdata:
            ## Get trials
            if sd == "experiment_trials":
                etrials = sdata["experiment_trials"]
    print(etrials)
    
def hpoconfig2csv(hpoconfigjson, benchmarkcsv, outputcsv, trial):
    list2 = []
    list1 = []
    with open(hpoconfigjson, "r") as f:
        data = json.load(f)
        
    with open("intermediate.csv", "w") as f:
        output = csv.writer(f)
        output.writerow(data[0].keys())
        for row in data:
            output.writerow(row.values())

    with open('intermediate.csv', 'r') as f:
        csv_reader = csv.reader(f, delimiter=',')
        for row in csv_reader:
            list1.append(row[0])
            list2.append(row[1])

    list1.remove("tunable_name")
    list2.remove("tunable_value")

    list1.insert(0, "Trial")
    list2.insert(0, trial)
    ## TODO : header of benchmark data will be missing if trial 0 is pruned.
    if os.path.isfile(benchmarkcsv):
        with open(benchmarkcsv, 'r') as f:
            csv_reader = csv.DictReader(f, delimiter=',')
            header_dict = dict(list(csv_reader)[0])
            header_list = list(header_dict.keys())
            list1.extend(header_list)
        with open(benchmarkcsv, 'r') as f:
            reader = csv.reader(f, delimiter=',')
            data_list = list(reader)[1]
            list2.extend(data_list)
    
    #print(list1)
    #print(list2)
    with open(outputcsv, 'a', newline='') as f:
        output = csv.writer(f)
        if trial == "0":
            output.writerow(list1)
        output.writerow(list2)

def alltrialsoutput(inputfile, outputfile, trial):
    list1 = []
    list2 = []
    if os.path.isfile(inputfile):
        with open(inputfile, 'r') as f:
            csv_reader = csv.DictReader(f, delimiter=',')
            header_dict = dict(list(csv_reader)[0])
            header_list = list(header_dict.keys())
            list1.extend(header_list)
        with open(inputfile, 'r') as f:
            reader = csv.reader(f, delimiter=',')
            data_list = list(reader)[1]
            list2.extend(data_list)
        list1.insert(0, "Trial")
        list2.insert(0, trial)

    #print(list1)
    #print(list2)
    with open(outputfile, 'a', newline='') as f:
        output = csv.writer(f)
        if trial == "0":
            output.writerow(list1)
        output.writerow(list2)

headerlist = {'INSTANCES','THROUGHPUT_RATE_3m','RESPONSE_TIME_RATE_3m','MAX_RESPONSE_TIME','RESPONSE_TIME_50p','RESPONSE_TIME_95p','RESPONSE_TIME_97p','RESPONSE_TIME_99p','RESPONSE_TIME_99.9p','RESPONSE_TIME_99.99p','RESPONSE_TIME_99.999p','RESPONSE_TIME_100p','CPU_USAGE','MEM_USAGE','CPU_MIN','CPU_MAX','MEM_MIN','MEM_MAX','THRPT_PROM_CI','RSPTIME_PROM_CI','THROUGHPUT_WRK','RESPONSETIME_WRK','RESPONSETIME_MAX_WRK','RESPONSETIME_STDEV_WRK','WEB_ERRORS','THRPT_WRK_CI','RSPTIME_WRK_CI','DEPLOYMENT_NAME','NAMESPACE','IMAGE_NAME','CONTAINER_NAME'}
